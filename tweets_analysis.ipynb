{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "k4ig6YjDRKuy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "from textblob import TextBlob\n",
        "\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.classification import RandomForestClassifier, NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyspark"
      ],
      "metadata": {
        "id": "tqfgWbhBonf7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"Catch_tweets\").getOrCreate()\n",
        "\n",
        "# Load the CSV file into a Spark DataFrame\n",
        "tweets_data = spark.read.csv(\"/content/drive/MyDrive/Data/tweets.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Define a user-defined function (UDF) for sentiment analysis using TextBlob\n",
        "def analyze_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    # Classify polarity as 'positive', 'negative', or 'neutral'\n",
        "    if analysis.sentiment.polarity > 0:\n",
        "        return 'positive'\n",
        "    elif analysis.sentiment.polarity < 0:\n",
        "        return 'negative'\n",
        "\n",
        "    else:\n",
        "        return 'neutral'"
      ],
      "metadata": {
        "id": "3k0SSEjRYgIg"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the UDF with Spark\n",
        "sentiment_udf = udf(analyze_sentiment, StringType())"
      ],
      "metadata": {
        "id": "tDVuP2VgYmjQ"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_data = tweets_data.withColumn(\"sentiments\", sentiment_udf(\"tweets\"))"
      ],
      "metadata": {
        "id": "Qgd23p0EZJ4h"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the resulting DataFrame\n",
        "tweets_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxDHqZqqZLyO",
        "outputId": "17df165e-7ba1-4440-d6c9-d9f1eca3fb5c"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------------+--------+---------------+--------------------+----------+\n",
            "|        id|               date|    flag|       username|              tweets|sentiments|\n",
            "+----------+-------------------+--------+---------------+--------------------+----------+\n",
            "|1467810672|2009-04-06 22:19:49|NO_QUERY|  scotthamilton|is upset that he ...|   neutral|\n",
            "|1467810917|2009-04-06 22:19:53|NO_QUERY|       mattycus|@Kenichan I dived...|  positive|\n",
            "|1467811184|2009-04-06 22:19:57|NO_QUERY|        ElleCTF|my whole body fee...|  positive|\n",
            "|1467811193|2009-04-06 22:19:57|NO_QUERY|         Karoli|@nationwideclass ...|  negative|\n",
            "|1467811372|2009-04-06 22:20:00|NO_QUERY|       joy_wolf|@Kwesidei not the...|  positive|\n",
            "|1467811592|2009-04-06 22:20:03|NO_QUERY|        mybirch|         Need a hug |   neutral|\n",
            "|1467811594|2009-04-06 22:20:03|NO_QUERY|           coZZ|@LOLTrish hey  lo...|  positive|\n",
            "|1467811795|2009-04-06 22:20:05|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|   neutral|\n",
            "|1467812025|2009-04-06 22:20:09|NO_QUERY|        mimismo|@twittera que me ...|   neutral|\n",
            "|1467812416|2009-04-06 22:20:16|NO_QUERY| erinx3leannexo|spring break in p...|  negative|\n",
            "|1467812579|2009-04-06 22:20:17|NO_QUERY|   pardonlauren|I just re-pierced...|   neutral|\n",
            "|1467812723|2009-04-06 22:20:19|NO_QUERY|           TLeC|@caregiving I cou...|   neutral|\n",
            "|1467812771|2009-04-06 22:20:19|NO_QUERY|robrobbierobert|@octolinz16 It it...|   neutral|\n",
            "|1467812784|2009-04-06 22:20:20|NO_QUERY|    bayofwolves|@smarrison i woul...|  positive|\n",
            "|1467812799|2009-04-06 22:20:20|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|   neutral|\n",
            "|1467812964|2009-04-06 22:20:22|NO_QUERY| lovesongwriter|Hollis' death sce...|   neutral|\n",
            "|1467813137|2009-04-06 22:20:25|NO_QUERY|       armotley|about to file taxes |   neutral|\n",
            "|1467813579|2009-04-06 22:20:31|NO_QUERY|     starkissed|@LettyA ahh ive a...|  positive|\n",
            "|1467813782|2009-04-06 22:20:34|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|   neutral|\n",
            "|1467813985|2009-04-06 22:20:37|NO_QUERY|         quanvu|@alydesigns i was...|  positive|\n",
            "+----------+-------------------+--------+---------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert label into integer\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "\n",
        "sentiment_mapping = {\"positive\": 1, \"negative\": 2, \"neutral\": 0}\n",
        "\n",
        "# Create a new column 'label' using when and otherwise\n",
        "tweets_data = tweets_data.withColumn(\n",
        "    \"label\",\n",
        "    when(tweets_data[\"sentiments\"] == \"positive\", sentiment_mapping[\"positive\"])\n",
        "    .when(tweets_data[\"sentiments\"] == \"negative\", sentiment_mapping[\"negative\"])\n",
        "    .otherwise(sentiment_mapping[\"neutral\"])\n",
        ")\n"
      ],
      "metadata": {
        "id": "5aG1P717w2Yh"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_data.show(n=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TR98JrzuUIk",
        "outputId": "07d25000-9090-45d5-f743-a26d53b15662"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------------+--------+-------------+--------------------+----------+-----+\n",
            "|        id|               date|    flag|     username|              tweets|sentiments|label|\n",
            "+----------+-------------------+--------+-------------+--------------------+----------+-----+\n",
            "|1467810672|2009-04-06 22:19:49|NO_QUERY|scotthamilton|is upset that he ...|   neutral|    0|\n",
            "|1467810917|2009-04-06 22:19:53|NO_QUERY|     mattycus|@Kenichan I dived...|  positive|    1|\n",
            "|1467811184|2009-04-06 22:19:57|NO_QUERY|      ElleCTF|my whole body fee...|  positive|    1|\n",
            "|1467811193|2009-04-06 22:19:57|NO_QUERY|       Karoli|@nationwideclass ...|  negative|    2|\n",
            "+----------+-------------------+--------+-------------+--------------------+----------+-----+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = tweets_data.select('tweets','label')\n",
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5y3Y1vOuDbp",
        "outputId": "f266001a-92ff-4294-e3e2-c28c2d323762"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|              tweets|label|\n",
            "+--------------------+-----+\n",
            "|is upset that he ...|    0|\n",
            "|@Kenichan I dived...|    1|\n",
            "|my whole body fee...|    1|\n",
            "|@nationwideclass ...|    2|\n",
            "|@Kwesidei not the...|    1|\n",
            "|         Need a hug |    0|\n",
            "|@LOLTrish hey  lo...|    1|\n",
            "|@Tatiana_K nope t...|    0|\n",
            "|@twittera que me ...|    0|\n",
            "|spring break in p...|    2|\n",
            "|I just re-pierced...|    0|\n",
            "|@caregiving I cou...|    0|\n",
            "|@octolinz16 It it...|    0|\n",
            "|@smarrison i woul...|    1|\n",
            "|@iamjazzyfizzle I...|    0|\n",
            "|Hollis' death sce...|    0|\n",
            "|about to file taxes |    0|\n",
            "|@LettyA ahh ive a...|    1|\n",
            "|@FakerPattyPattz ...|    0|\n",
            "|@alydesigns i was...|    1|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SBrszw8e7rYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Divide data into 70% for training, 30% for testing\n",
        "\n",
        "(trainingData , testingData) = data.randomSplit([0.7, 0.3])\n",
        "\n",
        "# train_rows = trainingData.count()\n",
        "# test_rows = testingData.count()\n",
        "\n",
        "# print (\"Training data rows:\", train_rows, \"; Testing data rows:\", test_rows)"
      ],
      "metadata": {
        "id": "O8iw7pJZ_taq"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    # You can customize this function based on your specific cleaning requirements\n",
        "    # For now, let's remove mentions, hashtags, and special characters\n",
        "    cleaned_text = ' '.join([word for word in text.split() if not word.startswith('@') and not word.startswith('#')])\n",
        "    cleaned_text = ''.join(e for e in cleaned_text if e.isalnum() or e.isspace())\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "4tpVMG3OGBvB"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_udf = udf(clean_text, StringType())"
      ],
      "metadata": {
        "id": "hf1g5n-8GB1r"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingData = trainingData.withColumn(\"tweets\", clean_udf((\"tweets\")))"
      ],
      "metadata": {
        "id": "SDVQP9KxGB5E"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Clean training data***"
      ],
      "metadata": {
        "id": "m2LLIXuPqMnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate \"tweets\" into individual words using tokenizer\n",
        "tokenizer = Tokenizer(inputCol=\"tweets\", outputCol=\"tweetWords\")\n",
        "tokenizedTrain = tokenizer.transform(trainingData)\n",
        "tokenizedTrain.show(truncate=False, n=5)"
      ],
      "metadata": {
        "id": "ylOXNsBjWhVi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d2275ee-c2f4-474d-8816-80bfec742484"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------+\n",
            "|tweets                                                                      |label|tweetWords                                                                                 |\n",
            "+----------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------+\n",
            "|exhausted                                                                   |2    |[exhausted]                                                                                |\n",
            "|is so sad for my APL friend                                                 |2    |[is, so, sad, for, my, apl, friend]                                                        |\n",
            "|I HAVE NOOOOOOOOOO FRIENDS ON TWITTER IT MAKES ME SAD WILL SOMEONE FOLLOW ME|2    |[i, have, noooooooooo, friends, on, twitter, it, makes, me, sad, will, someone, follow, me]|\n",
            "|just practisinghow I feel                                                   |0    |[just, practisinghow, i, feel]                                                             |\n",
            "|i just want to hear from you i guess thats asking too much                  |1    |[i, just, want, to, hear, from, you, i, guess, thats, asking, too, much]                   |\n",
            "+----------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing stop words (unimportant words to be features)\n",
        "swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(),\n",
        "                       outputCol=\"MeaningfulWords\")\n",
        "SwRemovedTrain = swr.transform(tokenizedTrain)\n",
        "SwRemovedTrain.show(truncate=False, n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FxbRl98Whb3",
        "outputId": "7e2d62af-872e-48f2-e472-184ec214210e"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------+------------------------------------------------------------+\n",
            "|tweets                                                                      |label|tweetWords                                                                                 |MeaningfulWords                                             |\n",
            "+----------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------+------------------------------------------------------------+\n",
            "|exhausted                                                                   |2    |[exhausted]                                                                                |[exhausted]                                                 |\n",
            "|is so sad for my APL friend                                                 |2    |[is, so, sad, for, my, apl, friend]                                                        |[sad, apl, friend]                                          |\n",
            "|I HAVE NOOOOOOOOOO FRIENDS ON TWITTER IT MAKES ME SAD WILL SOMEONE FOLLOW ME|2    |[i, have, noooooooooo, friends, on, twitter, it, makes, me, sad, will, someone, follow, me]|[noooooooooo, friends, twitter, makes, sad, someone, follow]|\n",
            "|just practisinghow I feel                                                   |0    |[just, practisinghow, i, feel]                                                             |[practisinghow, feel]                                       |\n",
            "|i just want to hear from you i guess thats asking too much                  |1    |[i, just, want, to, hear, from, you, i, guess, thats, asking, too, much]                   |[want, hear, guess, thats, asking, much]                    |\n",
            "+----------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------+------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting words feature into numerical feature withHashingTF funtion for model training\n",
        "hashTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")\n",
        "numericTrainData = hashTF.transform(SwRemovedTrain).select(\n",
        "    'label', 'MeaningfulWords', 'features')\n",
        "numericTrainData.show(truncate=False, n=3)"
      ],
      "metadata": {
        "id": "ICPWZITNBkwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e91168f7-4069-4aa3-9a2f-aadaa2b477bb"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------------------------------------------------------+---------------------------------------------------------------------------------------+\n",
            "|label|MeaningfulWords                                             |features                                                                               |\n",
            "+-----+------------------------------------------------------------+---------------------------------------------------------------------------------------+\n",
            "|2    |[exhausted]                                                 |(262144,[148003],[1.0])                                                                |\n",
            "|2    |[sad, apl, friend]                                          |(262144,[74520,74989,125638],[1.0,1.0,1.0])                                            |\n",
            "|2    |[noooooooooo, friends, twitter, makes, sad, someone, follow]|(262144,[1512,125638,130047,148039,182401,199581,213767],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
            "+-----+------------------------------------------------------------+---------------------------------------------------------------------------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5CdfvIMdZCsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Modeling***"
      ],
      "metadata": {
        "id": "8xoy8otzq6BK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train our classifier model using training data\n",
        "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\",\n",
        "                        maxIter=10, regParam=0.01)\n",
        "model = lr.fit(numericTrainData)\n",
        "print (\"Training is done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXNLABBD2fmm",
        "outputId": "db4d12d0-2748-4121-8d54-42f530420b48"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training is done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testingData = testingData.withColumn(\"tweets\", clean_udf((\"tweets\")))"
      ],
      "metadata": {
        "id": "1-nN8dHy8vGg"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Prepare testing data\n",
        "tokenizedTest = tokenizer.transform(testingData)\n",
        "SwRemovedTest = swr.transform(tokenizedTest)\n",
        "numericTest = hashTF.transform(SwRemovedTest).select(\n",
        "    'Label', 'MeaningfulWords', 'features')\n",
        "numericTest.show(truncate=False, n=2)"
      ],
      "metadata": {
        "id": "IaX0RW_a2frx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0ce215-d64d-4833-db9e-725d6c45021c"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------------------------+------------------------------------------------------+\n",
            "|Label|MeaningfulWords             |features                                              |\n",
            "+-----+----------------------------+------------------------------------------------------+\n",
            "|1    |[miss, much, already]       |(262144,[2306,76764,232735],[1.0,1.0,1.0])            |\n",
            "|1    |[missed, new, moon, trailer]|(262144,[64344,89833,165360,201103],[1.0,1.0,1.0,1.0])|\n",
            "+-----+----------------------------+------------------------------------------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict testing data and calculate the accuracy model\n",
        "prediction = model.transform(numericTest)\n",
        "predictionFinal = prediction.select(\n",
        "    \"MeaningfulWords\", \"prediction\", \"Label\")\n",
        "predictionFinal.show(n=4, truncate = False)\n",
        "correctPrediction = predictionFinal.filter(\n",
        "    predictionFinal['prediction'] == predictionFinal['Label']).count()\n",
        "totalData = predictionFinal.count()\n",
        "print(\"correct prediction:\", correctPrediction, \", total data:\", totalData,\n",
        "      \", accuracy:\", correctPrediction/totalData)"
      ],
      "metadata": {
        "id": "hOeVItYN2fvl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d23af344-cbc6-4ba7-fa37-9c504b0e0cee"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------+----------+-----+\n",
            "|MeaningfulWords                   |prediction|Label|\n",
            "+----------------------------------+----------+-----+\n",
            "|[miss, much, already]             |1.0       |1    |\n",
            "|[missed, new, moon, trailer]      |1.0       |1    |\n",
            "|[head, feels, like, bowling, ball]|0.0       |0    |\n",
            "|[heart, hurts, badly]             |2.0       |2    |\n",
            "+----------------------------------+----------+-----+\n",
            "only showing top 4 rows\n",
            "\n",
            "correct prediction: 424919 , total data: 480624 , accuracy: 0.8840985885016146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fahGLzck2fyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "limit_train_data = numericTrainData.limit(1000)"
      ],
      "metadata": {
        "id": "qfYamW4pwdSl"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# limit_train_data.show(n=3)"
      ],
      "metadata": {
        "id": "sn32DuMJw4bf"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForestClassifier\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10)"
      ],
      "metadata": {
        "id": "wwHedBZoJUef"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the RandomForest model\n",
        "model_rf = rf.fit(numericTrainData)"
      ],
      "metadata": {
        "id": "q4jSvl8SdCSL"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the testing set\n",
        "predictions_rf = model_rf.transform(numericTest)"
      ],
      "metadata": {
        "id": "pzNz1jXOdCZg"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the RandomForest model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"sentiments\", predictionCol=\"prediction\", metricName=\"accuracy\")"
      ],
      "metadata": {
        "id": "xStRz3yrdCfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_rf = evaluator.evaluate(predictions_rf)\n",
        "print(f\"RandomForest Accuracy: {accuracy_rf}\")"
      ],
      "metadata": {
        "id": "MeNAcwcNJUkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZMzF8HsedK6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q0LBdljxdK9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fShfzZStdK_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZtotjGOdLCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NaiveBayes\n",
        "nb = NaiveBayes(labelCol=\"label\", featuresCol=\"features\", smoothing=1.0, modelType=\"multinomial\")\n"
      ],
      "metadata": {
        "id": "8hElig95JUqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the NaiveBayes model\n",
        "model_nb = nb.fit(numericTrainData)"
      ],
      "metadata": {
        "id": "FrivcictJUtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the testing set\n",
        "predictions_nb = model_nb.transform(numericTest)"
      ],
      "metadata": {
        "id": "9D4rXVouJUwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the NaiveBayes model\n",
        "accuracy_nb = evaluator.evaluate(predictions_nb)\n",
        "print(f\"NaiveBayes Accuracy: {accuracy_nb}\")"
      ],
      "metadata": {
        "id": "Hb8uj7bf2f1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zSMqeWQo3tNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xyuR3wte3tQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q48JXFzF3tTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the DataFrame to a CSV file\n",
        "tweets_data.coalesce(1).write.csv('sentiments.csv', header=True, mode='overwrite')"
      ],
      "metadata": {
        "id": "ly8_Xc22ZONe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.read_csv('/content/sentiments.csv/open.csv', error_bad_lines=False)"
      ],
      "metadata": {
        "id": "UPS29r5zrLlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3"
      ],
      "metadata": {
        "id": "G9ipxApsrqOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import csv\n",
        "# field = [\"id\",\"date\",\"flag\",\"username\",\"tweets\",\"sentiments\"]\n",
        "# def spark_to_csv(data, file_path):\n",
        "#     \"\"\" Converts spark dataframe to CSV file \"\"\"\n",
        "#     with open(file_path, \"w\") as f:\n",
        "#         writer = csv.DictWriter(f, fieldnames= field)\n",
        "#         writer.writerow(dict(zip(fieldnames, fieldnames)))\n",
        "#         for row in data.toLocalIterator():\n",
        "#             writer.writerow(row.asDict())"
      ],
      "metadata": {
        "id": "chBfAj5maSdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3['date'] = pd.to_datetime(df3['date'].dt.strftime('%Y-%m-%d %H:%M:%S'))"
      ],
      "metadata": {
        "id": "ScWlVxNIdxlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3"
      ],
      "metadata": {
        "id": "3NBnD4qSmnqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tMom2h-SmoX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "owAp3Ivjsory"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}